%\VignetteIndexEntry{BeviMed Guide}
%\VignetteEngine{knitr::knitr}
<<setup,echo=FALSE,results='hide',include=FALSE, cache=FALSE>>=
library(knitr)
theme <- list(
	highlight=paste0(collapse="\n", c(
		"\\definecolor{fgcolor}{rgb}{0, 0, 0}",
		"\\newcommand{\\hlnum}[1]{\\textcolor[rgb]{0,0,0}{#1}}%",
		"\\newcommand{\\hlstr}[1]{\\textcolor[rgb]{0, 0, 0}{#1}}%",
		"\\newcommand{\\hlcom}[1]{\\textcolor[rgb]{0,0,0}{\\textit{#1}}}%",
		# dollar
		"\\newcommand{\\hlopt}[1]{\\textcolor[rgb]{0,0,0}{\\textbf{#1}}}%",
		"\\newcommand{\\hlstd}[1]{\\textcolor[rgb]{0,0,0}{#1}}%",
		# 'function'
		"\\newcommand{\\hlkwa}[1]{\\textcolor[rgb]{0,0,0}{\\textbf{#1}}}%",
		# assign to
		"\\newcommand{\\hlkwb}[1]{\\textcolor[rgb]{0,0,0}{\\textbf{#1}}}%",
		# argument names
		"\\newcommand{\\hlkwc}[1]{\\textcolor[rgb]{0,0,0}{#1}}%",
		# function names
		"\\newcommand{\\hlkwd}[1]{\\textcolor[rgb]{0,0,0}{\\textbf{#1}}}%",
		"\\let\\hlipl\\hlkwb"
	)),
	background="#ffffff",
	foreground="#000000"
)

knit_theme$set(theme)
opts_chunk$set(prompt=TRUE)
library(BeviMed)
set.seed(1)
N <- 10
k <- 5
af <- 0.1
G <- matrix(nrow=N, ncol=k, data=rbinom(n=N*k, size=2, prob=af))
k_patho <- 3
z <- c(rep(TRUE, k_patho), rep(FALSE, k-k_patho))
y <- apply(G[,z,drop=FALSE], 1, sum) > 0
@

\title{BeviMed Guide}
\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{placeins}
\usepackage{hyperref}
\usepackage{color}
\usepackage{enumerate}
\usepackage[margin=2cm]{geometry} 
\usepackage{bbm}
\usepackage[numbers,super,sort&compress]{natbib}
\usepackage{authblk}

\author{Daniel Greene}
\date{}

\bibliographystyle{ajhg}
\begin{document}
		\maketitle

\section{Introduction}
	BeviMed is a procedure for evaluating the evidence of association between allele configurations across rare variants within a genomic locus and a case/control label.
	It is capable of inferring the probability of association, and conditional on association, the probability of each mode of inheritance and probability of involvement of each variant. 
	It works by applying Bayesian inference to two models indexed by $\gamma$. 
	Under the model labelled $\gamma = 0$, the probability of the case label is independent of allele configuration at the given rare variant sites. 
	Under the model labelled $\gamma = 1$, the probability of the case label is linked to the configuration of alleles, a mode of inheritance and a latent partition of variants into \emph{pathogenic} and \emph{non-pathogenic} groups. 

	The aim of the package is to facilitate prioritisation of large numbers of loci and variants therein by rapid inference of the posterior distributions of $\gamma$, mode of inheritance parameter $m$, and indicator of pathogenicity across variants, $z$. 
	%This guide describes the package in the terms of the paper \cite{us}, although it is not necessary to read the paper in order to follow it. 
	Unless otherwise stated, $N$ refers to the number of individuals, $k$ refers to the number of rare variants, $m$ refers to the mode of inheritance (either $m_{\text{dom}}$ or $m_{\text{rec}}$), and `evidence' refers to the integrated likelihood of the data under a given model. The acronym `MOI' will often be used to refer to mode of inheritance.

\section{Functions and classes}
	\texttt{bevimed} is the key function in the package: it evaluates models $\gamma = 0$ and $\gamma = 1$ with respect to the input data, a logical length $N$ vector of case/control labels $y$, and an $N \times k$ integer matrix of allele counts $G$. It evaluates model $\gamma = 0$ by computing the log evidence directly using the function \texttt{gamma0\_evidence}. It performs inference on model $\gamma = 1$ conditional on each mode of inheritance separately by calling the function \texttt{bevimed\_m} (where the `\_m' is to be understood as `conditional upon a given mode of inheritance'). The output of the function gives you the posterior distributions of interest: 
	\begin{itemize}
		\item model indicator $\gamma$, i.e. $\mathbb{P}(\gamma = 1|y,G)$,
		\item mode of inheritance $m$ given association, i.e. $\mathbb{P}(m|\gamma=1,y,G)$,
		\item indicators of variant pathogenicity $z_j$ for $j = 1, \dots, k$ given mode of inheritance and association, i.e. $\mathbb{P}(z_j|m,\gamma=1,y,G)$.
	\end{itemize}

	\noindent\texttt{bevimed} is simple to apply: 
<<simple, echo=TRUE>>=
obj <- bevimed(y=y, G=G)
@
It returns an object of class \texttt{BeviMed}, which contains the whole output of the inference. A summary of the inference can be printed by evaluating the object in an interactive session:
<<print, echo=TRUE>>=
obj
@

It is a list containing slots:
\begin{itemize}
	\item \texttt{"parameters"}, a list of parameter values used to call the function.
	\item \texttt{"moi"}, a list of \texttt{BeviMed\_m} objects returned by the \texttt{bevimed\_m} function, one for each mode of inheritance (i.e. dominant and recessive). The \texttt{BeviMed\_m} class is a list containing samples from the posterior distributions of model parameters conditional on a given mode of inheritance (see help page \texttt{?bevimed\_m} for more details). As a list, the MOI specific results can be looked up by MOI using the \texttt{\$} operator, e.g. \texttt{x\$moi\$dominant}.  
\end{itemize}

\noindent The function \texttt{bevimed\_m} is an MCMC procedure which samples from the posterior distribution of parameters in model $\gamma = 1$. Each individual has an associated `minimum number of alleles at pathogenic variant sites' required to have a \emph{pathogenic configuration of alleles}. This is determined by the \texttt{min\_ac} argument (defaulting to $1$), and can be set to reflect the desired mode of inheritance. For example, in dominant inheritance, at least one pathogenic allele would render an allele configuration pathogenic, whilst for X-linked recessive inheritance, at least 1 and 2 pathogenic alleles would be required for a pathogenic configuration respectively for males and females. \texttt{bevimed} accepts a \texttt{ploidy} argument: an integer vector the same length as \texttt{y} which specifies the ploidy of each individual in the locus (defaulting to $2$). Internally, it uses this argument to set \texttt{min\_ac} automatically when it calls \texttt{bevimed\_m} based on mode of inheritance. 

\medskip
Objects of class \texttt{BeviMed} typically take a large quantity of memory, so summarising with \texttt{summary} --- which retains important summary statistics as a list --- may be useful when performing multiple applications. Specific summary statistics can be obtained by looking them up in these summary lists (see help page \texttt{?summary.BeviMed} for names used for each statistic), or by calling an `extract\_' function on a \texttt{BeviMed}/\texttt{BeviMed\_m} object:
\begin{itemize}
	\item \texttt{extract\_prob\_association}: get the probability of association from a \texttt{BeviMed} object, optionally broken down by mode of inheritance by specifying \texttt{by\_MOI=TRUE},
<<extract_prob_association, echo=TRUE>>=
extract_prob_association(obj)
extract_prob_association(obj, by_MOI=TRUE)
@
	\item \texttt{extract\_prob\_pathogenic}: get marginal probabilities of pathogenicity for each variant from a \texttt{BeviMed} object,
	\item \texttt{extract\_gamma1\_evidence}: get the log evidence of model $\gamma = 1$ for a mode of inheritance from a \texttt{BeviMed\_m} object,
	\item \texttt{extract\_conditional\_prob\_pathogenic}: get a vector of probabilities of pathogenicity individual variants from a \texttt{BeviMed\_m} object.
<<extract_conditional_prob_pathogenic, echo=TRUE>>=
extract_conditional_prob_pathogenic(obj$moi$dominant)
@
	\item \texttt{extract\_expected\_explained}: get the expected number of cases with a pathogenic configuration of alleles from a \texttt{BeviMed\_m} object,
	\item \texttt{extract\_explaining\_variants}: get the expected number of pathogenic variants for which cases harbour rare alleles from a \texttt{BeviMed\_m} object.
\end{itemize}

Each of these functions has an equivalent one by the same name without the `extract\_' prefix which can be called with the same raw arguments as \texttt{bevimed}/\texttt{bevimed\_m}: $y, G, \dots$, etc.
<<prob_association, echo=TRUE>>=
prob_association(y=y, G=G)
@
Note that the result of calling \texttt{prob\_association} is slightly different due to Monte Carlo error as the inference procedure has been repeated. 

\medskip
\texttt{bevimed} passes arguments to \texttt{bevimed\_m} through the `\texttt{...}' argument. However, sometimes it is preferable to pass different arguments to \texttt{bevimed\_m} depending on mode of inheritance. \texttt{bevimed} therefore allows mode of inheritance specific arguments to be passed through \texttt{dominant\_args} and \texttt{recessive\_args}, which should be named lists of arguments then only used in the corresponding calls to \texttt{bevimed\_m}. For example, it might be thought that fewer variants would be linked to disease given a dominant mode of inheritance than would given recessive inheritance, in which case \texttt{dominant\_args} could be used to pass a prior with a lower mean to the dominant application of \texttt{bevimed\_m}.

\section{Priors on model parameters}

The user can control the prior distributions of the model parameters when applying the inference functions \texttt{bevimed}, \texttt{bevimed\_m} and \texttt{gamma0\_evidence} as listed below. 
	\begin{itemize}
		\item The probability of association, $\mathbb{P}(\gamma = 1|y)$, with argument \texttt{prior\_prob\_association} in the \texttt{bevimed} function (defaults to $0.01$).
		\item The probability of dominant inheritance given association, $\mathbb{P}(m=m_{\text{dom}})$, with the \texttt{prior\_prob\_dominant} in the \texttt{bevimed} function (defaults to $0.5$).
		\item The hyper parameters of the Beta prior for the probability $\tau_0$ of observing the case label under model $\gamma = 0$. Values for the hyper parameters can be passed to the \texttt{bevimed} and \texttt{gamma0\_evidence} functions as the \texttt{tau0\_shape} argument (defaults to a vague parameterisation of $\alpha = \beta = 1$).
		\item The hyper parameters of the Beta prior for $\tau$ and $\pi$, respectively the probabilities of observing the case label for individuals with non-pathogenic and pathogenic allele configurations under model $\gamma = 1$. The default for $\tau$ is the same as for $\tau_0$, but the default for $\pi$ has a mean close to $1$, as typically for rare diseases the variants are high penetrance, i.e. have a high probability of causing the disease phenotype. Values for these hyper parameters can be passed as arguments \texttt{tau\_shape} and \texttt{pi\_shape} to the \texttt{bevimed} and \texttt{bevimed\_m} functions.

		\item The prior on the indicators of variant pathogenicity, $z$. By default, all variants have a shared prior on their probability of pathogenicity, $z_j \sim \text{Bernoulli}(\omega)$ with $\omega \sim \text{Beta}(\alpha=2, \beta=8)$. The hyper parameters for $\omega$ can be specified by the user using the parameter \texttt{omega\_shape}. 
	However the user can also control the prior on pathogenicity for individual variants. This is done using the \texttt{variant\_weights} parameter, a numeric vector of length $k$ labelled $c$ in the model specification. The effect of the $c$ values is given by the logistic equation:
		\begin{align*}
			 z_j &\sim \text{Bernoulli}(p_j),
			\\ \text{logit}\, p_j &= \omega + \phi c_j,
			\\ \text{log}\, \phi &\sim \text{N}(\mu_{\phi}, \sigma^2_{\phi}),
		\end{align*}
		where $\phi$ is the scaling factor for $c$. By default, $c$ is centralised on $0$ so that $\omega$ is interpretable as the global rate of pathogenicity in the locus, and $\phi$ has a mean of $1$, so $c_j$ is interpretable as a shift in the log odds on the prior probability of variant $j$ being pathogenic. The raw values of $c$ as given in the \texttt{variant\_weights} arguments will be used if the parameter \texttt{standardise\_weights} is set to \texttt{FALSE}. The hyper parameters $\mu_{\phi}$ and $\sigma_{\phi}$ for the prior distribution of $\log \phi$ are respectively represented by arguments \texttt{log\_phi\_mean} and \texttt{log\_phi\_sd}. Hyper parameters for $\omega$ and $\phi$ and the values for $c$ can be passed to functions \texttt{bevimed} and \texttt{bevimed\_m}. 

		Estimating the scaling factor $\phi$ in this way has the advantage of maintaining power even when the weights are counter-productive, as $\phi$ can take values close to $0$ making the weights redundant. However, it is possible to make the effect of variant weights $c$ fixed by setting the parameter \texttt{estimate\_phi} to \texttt{FALSE}, in which case $\phi$ is fixed at $1$. 
	\end{itemize}

\section{Application to real data}

	It is an assumption of model $\gamma = 1$ that alleles are \emph{identitical by state} rather than by descent.  
	This would typically be the case if only unrelated individuals are included in the analysis, and variants are filtered for low allele frequency across all ethnic groups.  
	It is therefore recommend to take these steps in order to set $G$. 
	Various software is available for performing these tasks: as an example `SAMtools' and `KING' can be used for variant filtering and inferring relatedness respectively. 
	There is also various software for reading VCF files into \texttt{R}. The `BeviMed with VCFs' vignette contains instructions on how to read allele counts across variants in a given locus into \texttt{R} from a VCF file directly as a matrix using simple functions depending on the program `tabix'. However, although this method could be effective for testing a single locus, typically testing association between a disease and multiple loci is required, in which case reading variants belonging to multiple loci at the same time is likely to be more efficient. Often, it will be most effective to read data for as many variants as possible into memory (e.g. breaking up the VCF by chromosome), and looping through loci one at a time, applying \texttt{bevimed} the allele count matrix of its variants. 
	Typically loci would correspond to genes, but it is also applicable to non-coding loci, for example, transcription factor binding sites. In order to increase power, variants which are unlikely to be involved in disease can be filtered out, or have their probability of pathogenicity down-weighted using the \texttt{variant\_weights} parameter. For example, synonymous variants could be removed, and loss-of-function variants could be up-weighted. One could also create multiple sets of variants corresponding to a single locus: for example, a set containing only loss-of-function variants and a set containing all loss-of-function, missense and UTR variants. One could then assign a prior probability of association to each set, and the posterior probability of association with each set could then be inferred by computing the evidence for each one in turn and combining with the prior probabilities.

\medskip
Although typically testing association between a disease and multiple loci is required, \texttt{BeviMed} only provides procedures for dealing with a single locus. This is because most of the time such an analysis is computationally expensive due to the large number of applications required or large quantity of genetic data which must be loaded, and full control is required in order to best exploit the resources available. Here we provide a simple example script which applies the inference to multiple loci and tabulates the results with columns for gene name, posterior probability of association and probability of dominant inheritance given the association.
Let \texttt{chr1genes} be a \texttt{data.frame} of chromosome 1 genes with columns for name, start position and end positon (the `biomaRt' package could be used to obtain such a table), and \texttt{y} be a logical vector indicating disease status, the same length as the number of samples in the VCF.

<<multiple, eval=FALSE, echo=TRUE>>=
source(paste0(system.file(package="BeviMed", "/scripts/vcf.R")))
all_variants <- vcf2matrix("my-vcf.vcf.gz", chr="1", from=1, to=1e9, include_variant_info=TRUE)
row_indices_per_gene <- lapply(1:nrow(chr1genes), function(i) {
	which(all_variants$info$POS >= chr1genes$start[i] & all_variants$info$POS <= chr1genes$end[i])
})
names(row_indices_per_gene) <- chr1genes$gene

results <- mclapply(
	mc.cores=16L,
	X=chr1genes$gene,
	FUN=function(gene) {
		G <- all_variants$G[variant_inds[[gene]],,drop=FALSE]
		c(
			list(gene=gene), 
			summary(bevimed(y=y, G=G))) })

results_table <- do.call(what=rbind, lapply(results, function(x) data.frame(
	Gene=x[["gene"]],
	`Prob. assoc`=sum(x[["prob_association"]]),
	`Prob. dominance`=x[["prob_association"]]["dominant"]/sum(x[["prob_association"]]),
	check.names=FALSE,
	stringsAsFactors=FALSE
)))

@

\section{Performance and tuning}
As an MCMC based procedure, statistics produced by \texttt{bevimed} have Monte Carlo error. In the implementation in the \texttt{BeviMed} package, $z$ is the only parameter which is sampled and is updated using Gibbs sampling of each component $z_j$ in turn. If variant weights are included, $\omega$ and $\phi$ are also sampled using Metropolis-Hastings within Gibbs steps, causing estimates of the evidence to have higher variance for the same number of samples. By default, \texttt{bevimed} draws $1,000$ samples from each of $7$ tempered chains in the MCMC algorithm, running at temperatures $t = \left(\frac{l}{6} \right)^2$ for $l \in \{ 0,1,\ldots,6 \}$. We have found that this parameterisation leads to quick execution and stable results for sample sizes up to $5,000$ and loci containing over $2,000$ variants, also allowing for the inclusion of variant weights. However, if much larger sample sizes or larger numbers of variants are used --- particularly if variant weights are included --- it may become necessary to modify the parameters controlling the sampling routine in order to improve the accuracy of the results. Strategies for doing this include:
\begin{itemize}
	\item increase the number of samples drawn per tempered chain using the \texttt{samples\_per\_chain} argument, 
	\item increase the number tempered chains or change the distribution of temperatures using the \texttt{temperatures} argument,
	\item pass the \texttt{tune\_temps} argument to \texttt{bevimed}, specifying the number of temperatures to select by interval bisection for use in the final application,
	\item if estimating $\phi$ and $\omega$, set \texttt{tune\_omega\_and\_phi\_proposal\_sd=TRUE} in the call to \texttt{bevimed} in order to adaptively tune the standard deviations of the Metropolis-Hastings proposal distributions so that the acceptance rate falls within a given range, defaulting to $[0.3, 0.7]$. If this option is used, a tuning run of the MCMC algorithm is applied, which estimates a proposal standard deviation for each temperature using successive blocks of \texttt{tune\_block\_size} samples until the desired acceptance rate is obtained.
\end{itemize}
It is also possible to instruct \texttt{bevimed\_m} to halt sampling once the estimated evidence lies within a given confidence interval, or once there is sufficient confidence that the evidence is greater than some threshold. The latter might be useful, for instance, if many regions were being tested for association and only those with very strong evidence for association were of interest). By default, \texttt{bevimed\_m} does not attempt to stop sampling, and always draws \texttt{samples\_per\_chain} samples for each tempered chain. In terms of the argument names, by setting \texttt{stop\_early=TRUE}, \texttt{bevimed\_m} draws up to \texttt{blocks} batches of \texttt{samples\_per\_chain} samples, stopping as soon as the estimated log evidence lies within a confidence interval of width \texttt{tolerance} (defaults to 1) with confidence of \texttt{confidence} (defaults to 0.95) based on \texttt{simulations} simulations (defaults to $1,000$), or as soon as there is \texttt{confidence} confidence that it is below \texttt{log\_evidence\_threshold}.

\end{document}




